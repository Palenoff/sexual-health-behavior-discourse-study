{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpale\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\kpale\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import analysis_toolbox as at\n",
    "import pandas as pd\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "platform = 'Kindertelefoon'\n",
    "working_dir = Path('C:\\\\SHB\\\\',platform)\n",
    "type = 'discussion_initiators'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(working_dir.joinpath(platform + '_' + type +'_key_users.csv'))\n",
    "df_comments = pd.read_csv(working_dir.joinpath(platform +'_comment_list.csv'))\n",
    "comments = df_comments[df_comments['Author_code'].isin(users_df['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  0.826599231769138 %\n",
      "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
      "                          random_state=100)\n",
      "[[5.00000000e-03 5.00000000e-03 5.43035196e-01 ... 5.00000000e-03\n",
      "  5.00000003e-03 5.00000000e-03]\n",
      " [5.31914895e-04 5.31914895e-04 5.31914896e-04 ... 5.31914894e-04\n",
      "  9.89893617e-01 5.31914895e-04]\n",
      " [3.59712232e-04 3.59712231e-04 3.59712246e-04 ... 3.59712232e-04\n",
      "  5.74659354e-01 3.59712230e-04]\n",
      " ...\n",
      " [5.00000000e-02 5.00000000e-02 5.00000000e-02 ... 5.00000000e-02\n",
      "  5.00000000e-02 5.00000000e-02]\n",
      " [8.33333336e-03 8.33333333e-03 8.33333334e-03 ... 8.33333333e-03\n",
      "  8.33333334e-03 8.33333333e-03]\n",
      " [1.00000003e-02 1.00000000e-02 2.10005360e-01 ... 1.00000000e-02\n",
      "  1.00000000e-02 1.00000000e-02]]\n"
     ]
    }
   ],
   "source": [
    "lda_model,vc,vectorizer = at.topic_modeling(comments['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 2}\n",
      "Best Log Likelihood Score:  -176467.47783139587\n",
      "Model Perplexity:  449.4625949719398\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable GridSearchCV object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_lda_model,grid_search_cv_model \u001b[39m=\u001b[39m at\u001b[39m.\u001b[39mselect_lda_model(vc)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable GridSearchCV object"
     ]
    }
   ],
   "source": [
    "best_lda_model,grid_search_cv_model = at.select_lda_model(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m at\u001b[39m.\u001b[39;49mplot_best_lda(best_lda_model)\n",
      "File \u001b[1;32mc:\\SHB\\Code\\analysis_toolbox.py:247\u001b[0m, in \u001b[0;36mplot_best_lda\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_best_lda\u001b[39m(model):\n\u001b[0;32m    246\u001b[0m     \u001b[39m# Get Log Likelyhoods from Grid Search Output\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     n_topics \u001b[39m=\u001b[39m topics_rng\n\u001b[0;32m    248\u001b[0m     log_likelyhoods_5 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mgrid_scores_ \u001b[39mif\u001b[39;00m gscore\u001b[39m.\u001b[39mparameters[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.5\u001b[39m]\n\u001b[0;32m    249\u001b[0m     log_likelyhoods_7 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mgrid_scores_ \u001b[39mif\u001b[39;00m gscore\u001b[39m.\u001b[39mparameters[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.7\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "at.plot_best_lda(grid_search_cv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpale\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pyLDAvis\u001b[39m.\u001b[39menable_notebook()\n\u001b[1;32m----> 2\u001b[0m panel \u001b[39m=\u001b[39m pyLDAvis\u001b[39m.\u001b[39;49msklearn\u001b[39m.\u001b[39;49mprepare(best_lda_model, vc, vectorizer, mds\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtsne\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m panel\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyLDAvis\\sklearn.py:94\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare\u001b[39m(lda_model, dtm, vectorizer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39m\"\"\"Create Prepared Data from sklearn's LatentDirichletAllocation and CountVectorizer.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m    See `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     opts \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mmerge(_extract_data(lda_model, dtm, vectorizer), kwargs)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m pyLDAvis\u001b[39m.\u001b[39mprepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyLDAvis\\sklearn.py:41\u001b[0m, in \u001b[0;36m_extract_data\u001b[1;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[0;32m     39\u001b[0m doc_lengths \u001b[39m=\u001b[39m _get_doc_lengths(dtm)\n\u001b[0;32m     40\u001b[0m term_freqs \u001b[39m=\u001b[39m _get_term_freqs(dtm)\n\u001b[1;32m---> 41\u001b[0m topic_term_dists \u001b[39m=\u001b[39m _get_topic_term_dists(lda_model)\n\u001b[0;32m     42\u001b[0m err_msg \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTopic-term distributions and document-term matrix\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     43\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mhave different number of columns, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[39massert\u001b[39;00m term_freqs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(vocab), \\\n\u001b[0;32m     46\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mTerm frequencies and vocabulary are of different sizes, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     47\u001b[0m      \u001b[39m.\u001b[39mformat(term_freqs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(vocab)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyLDAvis\\sklearn.py:34\u001b[0m, in \u001b[0;36m_get_topic_term_dists\u001b[1;34m(lda_model)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_topic_term_dists\u001b[39m(lda_model):\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m _row_norm(lda_model\u001b[39m.\u001b[39;49mcomponents_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, vc, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topic_keywords \u001b[39m=\u001b[39m at\u001b[39m.\u001b[39;49mshow_topics(vectorizer\u001b[39m=\u001b[39;49mvectorizer, lda_model\u001b[39m=\u001b[39;49mbest_lda_model, n_words\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)  \n\u001b[0;32m      2\u001b[0m \u001b[39m# Topic - Keywords Dataframe\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_topic_keywords \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(topic_keywords)\n",
      "File \u001b[1;32mc:\\SHB\\Code\\analysis_toolbox.py:265\u001b[0m, in \u001b[0;36mshow_topics\u001b[1;34m(vectorizer, lda_model, n_words)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_topics\u001b[39m(vectorizer, lda_model, n_words\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m):\n\u001b[0;32m    264\u001b[0m     keywords \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(vectorizer\u001b[39m.\u001b[39mget_feature_names())\n\u001b[1;32m--> 265\u001b[0m     topic_keywords \u001b[39m=\u001b[39m []\n\u001b[0;32m    266\u001b[0m     \u001b[39mfor\u001b[39;00m topic_weights \u001b[39min\u001b[39;00m lda_model\u001b[39m.\u001b[39mcomponents_:\n\u001b[0;32m    267\u001b[0m         top_keyword_locs \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mtopic_weights)\u001b[39m.\u001b[39margsort()[:n_words]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "topic_keywords = at.show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=20)  \n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99a86c7afeb291551c49aa8b725d382ddce6834076e71f3e457f0d861013d88b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
